{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json,os\n",
    "files=os.listdir('./strategy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2020-12-13_2020-12-13.json',\n",
       " '2020-12-14_2020-12-14.json',\n",
       " '2020-12-16_2020-12-16.json',\n",
       " '2020-12-17_2020-12-17.json']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import timedelta\n",
    "from os import listdir\n",
    "from datetime import datetime\n",
    "import json\n",
    "import sys\n",
    "import numpy as np\n",
    "from talib import abstract\n",
    "import talib\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from pandas_datareader import data as dtr\n",
    "from datetime import date, timedelta\n",
    "def get_time_li(date_,day_nums):\n",
    "    time_delta=1\n",
    "    day_count=0\n",
    "    date_list=[]\n",
    "#     file_dir=\"/home/mlb/res/stock/twse/json/\"\n",
    "    file_dir=\"stock_price/\"\n",
    "    date_time = datetime.strptime(date_, '%Y-%m-%d')\n",
    "    while True:\n",
    "        temp_date=(date_time+timedelta(days=-1*time_delta)).strftime(\"%Y-%m-%d\")\n",
    "        filepath=file_dir+temp_date+'.json'\n",
    "        if os.path.isfile(filepath):\n",
    "            day_count+=1\n",
    "            date_list.append(temp_date)\n",
    "        if day_count==day_nums:\n",
    "            return date_list\n",
    "            break \n",
    "        time_delta+=1\n",
    "def get_dates():\n",
    "#     mypath = \"/home/mlb/res/stock/twse/json/\"\n",
    "    mypath=\"stock_price/\"\n",
    "    # 取得所有檔案與子目錄名稱\n",
    "    files = listdir(mypath)\n",
    "    files.sort()         ##4113天\n",
    "    dates=[ele.strip('.json') for ele in files]\n",
    "    return dates\n",
    "def check_stock_exist(ele,data):\n",
    "    if ele in data and data[ele]['close']!='NULL' and data[ele]['open']!='NULL' and data[ele]['volume']!='NULL'and data[ele]['open']!='None' and data[ele]['close']!='None' and data[ele]['adj_close']!='NULL' and data[ele]['adj_close']!='None':\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def get_all_criteria(df):\n",
    "    ta_list = talib.get_functions()\n",
    "    for x in ta_list:\n",
    "        try:\n",
    "            # x 為技術指標的代碼，透過迴圈填入，再透過 eval 計算出 output\n",
    "            output = eval('abstract.'+x+'(df)')\n",
    "            # 如果輸出是一維資料，幫這個指標取名為 x 本身；多維資料則不需命名\n",
    "            output.name = x.lower() if type(output) == pd.core.series.Series else None\n",
    "            # 透過 merge 把輸出結果併入 df DataFrame\n",
    "            df = pd.merge(df, pd.DataFrame(output), left_on = df.index, right_on = output.index)\n",
    "            df = df.set_index('key_0')\n",
    "        except:\n",
    "            pass\n",
    "#             print(x,\" fail\")\n",
    "    return df\n",
    "def get_shift_day_with_criteria(use_day,df):\n",
    "    df_new=df.copy()\n",
    "    move_li=list(df_new.columns)\n",
    "    for day in range(1,use_day):\n",
    "        for ele in move_li:\n",
    "            df_new[ele+str(use_day-day)]= df_new[ele].shift(day)\n",
    "    return df_new\n",
    "\n",
    "def filetr_nan_drop_index(df):\n",
    "#     print('Total:',len(df))\n",
    "    for ele in list(df.columns):\n",
    "        if df[ele].isnull().sum() >len(df)/2:\n",
    "#             print(\"Drop:\",ele)\n",
    "            df=df.drop([ele],axis=1)\n",
    "    stock_cleanData = df.copy()\n",
    "    df.head()\n",
    "    stock_cleanData.dropna(inplace=True)\n",
    "    stock_cleanData.volume = stock_cleanData.volume.astype(float)\n",
    "    return stock_cleanData\n",
    "def scale_data(stock_cleanData,name,scale_type):\n",
    "    scaler = MinMaxScaler(feature_range=(0.1, 1.1))  ##price本身\n",
    "    feature_li=[ele for ele in list(stock_cleanData.columns) if ele not in ['high','low','open','close']]   \n",
    "    stock_cleanData[feature_li]=scaler.fit_transform(stock_cleanData[feature_li])\n",
    "\n",
    "    scaler_price = MinMaxScaler()                   ##其他param\n",
    "    scaler_price.fit([[stock_cleanData['high'].max()],[stock_cleanData['low'].min()]])\n",
    "    if scale_type==1:\n",
    "        scaler_dir='scaler/'+use_scaler[name]\n",
    "#         print(\"use_scaler_model\")\n",
    "        with open(scaler_dir, 'rb') as f:\n",
    "            scaler_price= pickle.load(f)\n",
    "    stock_cleanData[['high','low','open','close']]=scaler_price.transform(stock_cleanData[['high','low','open','close']])\n",
    "    return stock_cleanData\n",
    "\n",
    "def get_data(stock_number,date):\n",
    "    data_=dtr.DataReader(stock_number, \"yahoo\", \"2019-01-01\",date)\n",
    "    data_=data_.rename(columns={'High':'high','Low':'low','Open':'open','Close':'close','Volume':'volume'})\n",
    "    df= data_[data_.columns.tolist()[:-1]]\n",
    "    return df\n",
    "def strategy_tw50(date_,current_date):\n",
    "    models=listdir('models/')\n",
    "    use_model={}\n",
    "    stock_code=[]\n",
    "    for ele in models:\n",
    "        token=ele.split('_')\n",
    "        if token[4]!='nan':\n",
    "            if float(token[4])>0.65:\n",
    "                use_model[token[2]]=ele\n",
    "                stock_code.append(token[2])\n",
    "    scalers=listdir('scaler/')\n",
    "    use_scaler={ele.split('_')[0]:ele for ele in scalers}\n",
    "    \n",
    "    stock_data={ele:get_data(ele+'.TW',date_) for ele in stock_code}  \n",
    "    print(\"stock_code\",stock_code)\n",
    "    buy_list=[]\n",
    "    for stock in stock_data:\n",
    "        try:\n",
    "            t1=stock_data[stock]\n",
    "            t1=get_all_criteria(t1)\n",
    "            t1=get_shift_day_with_criteria(3,t1)\n",
    "            clean_data=filetr_nan_drop_index(t1)\n",
    "            print(stock)\n",
    "            clean_data=scale_data(clean_data,stock,0)\n",
    "\n",
    "            current_data=clean_data.iloc[-1]\n",
    "            predict_input=pd.DataFrame(dict(current_data),index=[0])\n",
    "            model_dir='models/'+use_model[stock]\n",
    "            with open(model_dir, 'rb') as f:\n",
    "                model = pickle.load(f)\n",
    "                output_y = model.predict(predict_input)\n",
    "                if output_y[0]:\n",
    "                    buy_list.append(stock)\n",
    "        except:\n",
    "            print(\"error:\",stock)\n",
    "    decision_set = []\n",
    "    for ele in buy_list:\n",
    "        curr_stock =stock_data[ele]\n",
    "        close_price=curr_stock.close.tolist()[-1]\n",
    "        curr_decision = {\n",
    "        \"code\": ele,\n",
    "        \"life\": 1,\n",
    "        \"type\": \"buy\",\n",
    "        \"weight\": 1,\n",
    "        \"open_price\": float(close_price),\n",
    "        \"close_high_price\":float(close_price)*1.02,\n",
    "        \"close_low_price\":float(close_price)*0.999      \n",
    "        }\n",
    "        decision_set.append(curr_decision)\n",
    "    print(date_, decision_set)\n",
    "    json.dump(decision_set, open(f'strategy/{current_date}_{current_date}.json', 'w'), indent=4)   \n",
    "    return stock_data\n",
    "now = datetime.now()\n",
    "current_date=now.strftime(\"%Y-%m-%d\")\n",
    "pre_day=now-timedelta(1)\n",
    "pre_date=pre_day.strftime(\"%Y-%m-%d\")\n",
    "print(\"date:\",current_date)\n",
    "strategy_tw50(pre_date,current_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date, timedelta\n",
    "now = datetime.now()\n",
    "current_date=now.strftime(\"%Y-%m-%d\")\n",
    "pre_day=now-timedelta(1)\n",
    "pre_date=pre_day.strftime(\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2020-12-19'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2020-12-20'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
